# AI 助手實踐筆記：從 Mini-Claw 探索生產級架構

這份文件紀錄了如何參考生產級 AI 助手專案 **OpenClaw**，打造出精簡版 `jack-mini-claw` 的過程。核心目標在於釐清具備「大腦」與「手腳」的 AI 助手其運作原理與架構。

---

## AI 助手五大組件

研究 OpenClaw 可以發現，一個完整的 AI 平台是由以下五個核心支柱構成：

1.  **網關 (Gateway)**：大腦總管，負責會話分配、歷史記憶與協定轉換。
2.  **思考引擎 (Agent Runtime)**：AI 的推理核心，決定「思考 -> 行動 -> 觀察」的循環。
3.  **通路適配器 (Connectors)**：負責與外部應用（如 Telegram, WhatsApp）對接的通訊橋樑。
4.  **工具系統 (Tooling/MCP)**：AI 的延伸手腳，讓其具備執行指令或存取外部資訊的能力。
5.  **安全沙盒 (Sandbox)**：最關鍵的安全環節，確保 AI 產出的指令在隔離環境中執行。

---

## 🛠️ 專案結構：`jack-mini-claw`

為了教學與學習，專案將複雜概念拆解為幾個核心檔案，運作邏輯如下：

*   **`bot.ts` (通路)**：對外通訊窗口，利用 `grammY` 套件與 Telegram API 對接。
*   **`ai.ts` (思考)**：與 Google Gemini 模型溝通的核心，負責定義 AI 可呼叫的「工具清單」。
*   **`executor.ts` (手腳)**：指令執行器，負責在系統中運行 Shell 指令（如 `ls`, `cat`）。
*   **`index.ts` (網關)**：程式主入口，負責黏合各組件並協調訊息流向。
*   **`memory.ts` (記憶)**：會話管理器，負責存取每個用戶的對話歷史，維持對話連貫性。

---

## 🔄 運作流程 (Workflow)

以「查看目錄檔案」的需求為例：

1.  **收件**：`bot.ts` 接收用戶訊息並傳遞至 `index.ts`。
2.  **思考**：`index.ts` 向 `ai.ts` 詢問意圖。Gemini 判斷需要執行指令，回傳標籤：「執行 `ls`」。
3.  **執行**：`index.ts` 調用 `executor.ts` 運行 `ls` 指令。
4.  **回報**：將執行結果傳回 `ai.ts` 總結，最終由 `bot.ts` 將內容發送給用戶。

---

## 🧠 進階實作原理

### 1. 會話記憶維護 (Memory)
透過 `memory.ts` 中的 Map 結構，利用 Telegram 提供的 `chatId` 識別不同用戶。在呼叫 Gemini API 時，將該用戶的紀錄傳入 `startChat({ history })`。
為了兼顧效能與 Token 成本，系統限制只保留最近 10 輪對話（採用先進先出原則）。

### 2. 指令執行安全性 (Security)
由於 AI 產出的指令具備潛在風險，`executor.ts` 實作了「指令黑名單 (Blacklist)」機制。
系統會在執行前掃描指令字串，若包含 `rm` (刪除)、`sudo` (最高權限) 或 `>` (重寫檔案) 等關鍵字，將立即攔截並拒絕執行。在生產環境中，建議進一步配合 Docker 沙盒等虛擬化環境來確保系統安全性。

---

## 📊 Mini-Claw 與 OpenClaw 的組件對應

| Mini-Claw 組件 | 對應 OpenClaw 位置 | 功能說明 |
| :--- | :--- | :--- |
| `bot.ts` | `src/connectors/` | 外部通訊協定處理 |
| `ai.ts` | `src/agent/` | 核心推理與工具定義 |
| `index.ts` | `src/gateway/` | 訊息分發與編排中心 |
| `executor.ts` | `src/sandbox/` | 指令執行的環境隔離 |

---

透過實作 `jack-mini-claw` 可以了解，一個完善的 AI 助手除了核心模型外，更需要整合**通訊通路的彈性**、**上下文記憶的連貫性**以及**執行環境的安全性**。

*整理日期：2026-02-06*
